% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/school_directory.R
\name{vz_get_directory}
\alias{vz_get_directory}
\title{Get school directory}
\usage{
vz_get_directory(
  tables = c("addresses", "schools", "locations", "specialisations"),
  ...,
  return_tibbles = FALSE,
  write_files = TRUE,
  dest_dir = getwd()
)
}
\arguments{
\item{tables}{a character vector of tables to retrieve. See ** Tables** below.}

\item{...}{key-value pairs of search fields. Use \code{vz_get_search_fields()}
to see a list of fields and their potential values.}

\item{return_tibbles}{Whether to return the data (if TRUE) or only download the files (if FALSE).}

\item{write_files}{Whether to write the XLS files locally.}

\item{dest_dir}{Directory in which to write XLS files. Defaults to working directory.}
}
\value{
A list of a \link[tibble:tibble-package]{tibbles} if return_tibbles = TRUE, a single tibble if only
one table name is passed \code{tables}, otherwise a character vector of paths
to the downloaded *.xls files.

if return_tibbles is TRUE, a named list of
\link[tibble:tibble-package]{tibbles}, with a tibble for each table in \code{tables}
with the corresponding name, unless the function was called with a \code{tables}
parameter of length one, in which case the result is a tibble;
if return_tibbles is FALSE, the result is a character vector of file paths.
Note that the downloaded XLS files are in fact HTML files and you are best
off loading them using \code{vz_load_directory()} and tidying with
\code{vz_load_directory}, though they can be opened in Excel too.
}
\description{
\lifecycle{experimental}
This function performs a search on the \href{http://stistko.uiv.cz/registr/vybskolrn.asp}{school directory at uiv.cz} and returns
the resulting export -  either the XLS file or the data, or both.
The school directory is a version of the school register: unlike the core
register, it contains contact information but lacks some other information
(such as unique address identification.) Use \code{vz_get_register()} for the core
register.
}
\section{Tables}{


Tables can include "addresses", "schools", "locations", "specialisations".
If you need more tables based on the same query (fields), pass them into
a single function call in order to avoid burdening the data provider's
server (the server needs to perform a search for each function call; there is no caching
and no data dumps are made available).
}

\section{What this does}{


The function
\itemize{
\item performs a search on the school directory at uiv.cz
\item by default the search is for all schools,
unless ... params are set to narrow down the search
\item traverses the results to the export links
\item downloads the XLS files
\item loads them into tibbles if return_tibbles is TRUE
}

This is the only way to get to the data - there are no static dumps available.
At the same time, no intense web scraping takes place - only individual
export files (max 4 per call) are downloaded the same way as
it would be done manually.
}

\section{Note}{


To avoid blitzing the data provider's server with many heavy requests:
\enumerate{
\item If you need more tables based on the same search, pass it in one call,
using the \code{tables} argument. This means that only one initial search is
peformed.
\item Only ask for the tables you need.
\item If you need a subset of the data, use the \code{fields} (...) argument
\item If you need multiple subsets of the data,
try to do that via the \code{fields} (...) argument too, though that may not always be
possible.
\item If you are downloading a large dump and reusing it in a
pipeline, keep the downloaded XLS files (or your own export) locally (setting
\code{write_files} to TRUE), use caching and avoid calling this function repeatedly
(ideally make any reruns conditional on the age of the stored export
or use a pipeline management framework such as {targets}.
}
}

\examples{
vz_get_directory("addresses", uzemi = "CZ010", return_tibbles = TRUE, write_files = TRUE)
}
